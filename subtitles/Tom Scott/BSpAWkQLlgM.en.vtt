WEBVTT
Kind: captions
Language: en

00:00:00.109 --> 00:00:03.270
 When online video had a different format, 

00:00:03.270 --> 00:00:05.630
 the search on YouTube was based on ... 

00:00:05.630 --> 00:00:07.570
 honesty, actually. 

00:00:07.570 --> 00:00:08.590
 After a video was uploaded 

00:00:08.590 --> 00:00:10.269
 you told YouTube what's in the video 

00:00:10.269 --> 00:00:13.200
 and YouTube looks at the title, description and tags 

00:00:13.200 --> 00:00:14.450
 and takes over from that point. 

00:00:14.450 --> 00:00:16.930
 People immediately tried to cheat. 

00:00:16.930 --> 00:00:18.020
 It became an arms race. 

00:00:18.020 --> 00:00:21.430
 Entering too many search terms, spamming tags, the 'reply girls' from 2012. 

00:00:21.430 --> 00:00:24.930
 If there was a way to discover YouTube's priority algorithm 

00:00:24.930 --> 00:00:26.550
 then spammers took advantage of it. 

00:00:26.550 --> 00:00:29.240
 Creators desperately changed the videos 

00:00:29.240 --> 00:00:31.620
 to what they thought YouTube wanted, 

00:00:31.620 --> 00:00:35.710
 on the basis of rumors, speculation and too much extrapolation 

00:00:35.710 --> 00:00:38.050
 from too little data. 

00:00:38.050 --> 00:00:41.400
 YouTube has recently stopped. 

00:00:41.400 --> 00:00:43.720
 The parent company - Google - learned this when 

00:00:43.720 --> 00:00:45.989
 online video was still in a RealPlayer window 

00:00:45.989 --> 00:00:49.470
 and connecting to the internet sounded like torturing a cat. 

00:00:49.470 --> 00:00:54.220
 If Google ever gave a hint how to get higher in the search results 

00:00:54.220 --> 00:00:57.420
 then there were the same spammers who took advantage of this. 

00:00:57.420 --> 00:00:58.540
 So the advice was always: 

00:00:58.540 --> 00:01:00.190
 Make good things 

00:01:00.190 --> 00:01:01.990
 We are looking for it. 

00:01:01.990 --> 00:01:04.680
 But on YouTube it is not the people who manage the algorithm 

00:01:04.680 --> 00:01:06.690
 who do not want to tell you how it works. 

00:01:06.690 --> 00:01:08.380
 They can not. 

00:01:08.380 --> 00:01:12.090
 There is proof: a document written by YouTube developers 

00:01:12.090 --> 00:01:17.150
 in which they explain that they use Google's research into machine learning, to recommend videos. 

00:01:17.150 --> 00:01:21.060
 That is the same kind of software that generates weird 'deep dream' images, 

00:01:21.060 --> 00:01:23.520
 that their text-to-speech sound so realistic 

00:01:23.520 --> 00:01:27.790
 and that the best Go player beat in his own game. 

00:01:27.790 --> 00:01:29.360
 I know this is a bit too easy, 

00:01:29.360 --> 00:01:31.799
 but machine-learning in the way that Google does 

00:01:31.799 --> 00:01:34.170
 is actually a black box. 

00:01:34.170 --> 00:01:35.650
 You give the neural network some input 

00:01:35.650 --> 00:01:37.520
 like the board game in Go. 

00:01:37.520 --> 00:01:40.470
 And it gives you output: a movement that may work. 

00:01:40.470 --> 00:01:41.700
 This output is being tested, 

00:01:41.700 --> 00:01:43.280
 and the result goes back into the box, 

00:01:43.280 --> 00:01:45.750
 and this process you repeat millions of times, 

00:01:45.750 --> 00:01:47.810
 and then the output is pretty good. 

00:01:47.810 --> 00:01:50.980
 But no one can look in the black box to see how it works: 

00:01:50.980 --> 00:01:54.141
 It is designed by a computer, for a computer. 

00:01:54.141 --> 00:01:56.460
 Neural networks are great for playing games 

00:01:56.460 --> 00:01:58.600
 with a clear score and points system. 

00:01:58.600 --> 00:02:00.930
 You win, or you lose. 

00:02:00.930 --> 00:02:04.220
 But training that black box on YouTube is messy. 

00:02:04.220 --> 00:02:06.540
 Not only is the behavior of people unpredictable and complex: 

00:02:06.540 --> 00:02:10.459
 finding out what counts as 'winning' is more difficult. 

00:02:10.459 --> 00:02:14.170
 If YouTube says to the algorithm "Show videos that people like", 

00:02:14.170 --> 00:02:16.500
 then each channel is politically completed 

00:02:16.500 --> 00:02:18.569
 where people click 'thumbs down' if they do not agree. 

00:02:18.569 --> 00:02:21.300
 And everyone with a small but vocal group is silenced 

00:02:21.300 --> 00:02:23.120
 who disagree with it. 

00:02:23.120 --> 00:02:26.700
 If YouTube says to the algorithm: "Ok, show videos that people share", 

00:02:26.700 --> 00:02:30.569
 then videos about private matters like medical problems and sex education are hidden 

00:02:30.569 --> 00:02:34.680
 and people with a small group of loyal but silent fans 

00:02:34.680 --> 00:02:36.050
 disappear in their own small world. 

00:02:36.050 --> 00:02:37.730
 And of course the YouTube developers want to 

00:02:37.730 --> 00:02:41.090
 that the algorithm recommends their own videos ... 

00:02:41.090 --> 00:02:45.129
 even if the rest of the world does not actually want to see it. 

00:02:45.129 --> 00:02:47.630
 So YouTube started, according to the document, 

00:02:47.630 --> 00:02:49.660
 with the assignment reasonable assignment: 

00:02:49.660 --> 00:02:52.170
 "increase the viewing time" 

00:02:52.170 --> 00:02:54.099
 But that has a few problems. 

00:02:54.099 --> 00:02:57.670
 A computer can not test quality or truth. 

00:02:57.670 --> 00:02:59.379
 At least, not yet. 

00:02:59.379 --> 00:03:01.030
 The system does not understand context. 

00:03:01.030 --> 00:03:03.910
 It can not determine the difference between current and reliable information 

00:03:03.910 --> 00:03:06.790
 and loose, paranoid conspiracy theories. 

00:03:06.790 --> 00:03:09.569
 I admit, most people can not. 

00:03:09.569 --> 00:03:12.330
 That's why these videos get so much attention, 

00:03:12.330 --> 00:03:14.120
 It can not determine the difference 

00:03:14.120 --> 00:03:16.580
 between videos that are suitable for children 

00:03:16.580 --> 00:03:18.800
 made with education in mind 

00:03:18.800 --> 00:03:22.349
 and scary unofficial efforts. 

00:03:22.349 --> 00:03:26.640
 It only knows what children click on and what they view. 

00:03:26.640 --> 00:03:30.989
 So yes, the algorithm knows to increase viewing time in the short term ... 

00:03:30.989 --> 00:03:33.740
 But a lot of recommended videos are debatable 

00:03:33.740 --> 00:03:35.880
 and possibly even harmful. 

00:03:35.880 --> 00:03:39.500
 And these are things that make advertisers very nervous. 

00:03:39.520 --> 00:03:41.800
 Remember, the algorithm is a black box. 

00:03:41.800 --> 00:03:43.180
 Nobody knows what it does. 

00:03:43.190 --> 00:03:46.459
 The only thing YouTube can do is change the feedback 

00:03:46.459 --> 00:03:50.810
 Telling what is good and bad. 

00:03:50.810 --> 00:03:54.319
 If YouTube has to review every video that is uploaded 

00:03:54.319 --> 00:03:57.299
 as 'safe' or 'unsafe' 

00:03:57.299 --> 00:04:01.129
 then they need more than 100,000 employees who are constantly working 

00:04:01.129 --> 00:04:03.150
 This again exposes them to legal problems: 

00:04:03.150 --> 00:04:05.060
 in most countries where YouTube has an office 

00:04:05.060 --> 00:04:07.060
 and you have an algorithm filtered 

00:04:07.060 --> 00:04:09.519
 and adjusts manually with complaints 

00:04:09.519 --> 00:04:10.900
 Then it's okay. 

00:04:10.900 --> 00:04:13.300
 But if you allow people to approve everything 

00:04:13.300 --> 00:04:14.510
 are you a publisher, 

00:04:14.510 --> 00:04:18.609
 and you can have to deal with expensive lawsuits. 

00:04:18.609 --> 00:04:21.069
 The ideal algorithm, the ideal black box, 

00:04:21.069 --> 00:04:22.349
 seen from YouTube's perspective 

00:04:22.349 --> 00:04:26.059
 would be one with the goal: "increase advertising revenue", 

00:04:26.059 --> 00:04:28.020
 given the long term 

00:04:28.020 --> 00:04:29.409
 and social issues 

00:04:29.409 --> 00:04:32.289
 and potential advertising boycotts and financial strategies 

00:04:32.289 --> 00:04:34.870
 and public opinion, which is suitable for children 

00:04:34.870 --> 00:04:36.940
 and ..... and about the truth. 

00:04:36.940 --> 00:04:39.409
 At this point you have something that 

00:04:39.409 --> 00:04:42.699
 the work of YouTube's senior management team can do. 

00:04:42.699 --> 00:04:45.279
 And AI is not that good yet. 

00:04:45.280 --> 00:04:47.340
 At least, not yet. 

00:04:47.900 --> 00:04:58.920
 Translation by: Ronald Bosveld 

